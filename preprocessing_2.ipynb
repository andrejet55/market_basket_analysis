{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em5psVRRiJmg"
      },
      "source": [
        "# Instacart market basket analysis\n",
        "\n",
        "## Data Mining and analysis CBD-3334_1\n",
        "\n",
        "* Andrea Franco - C0931897"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPDNrqjpiJmj"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrYb4KrdiJmk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9f8dgXliJmm"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtVOB_NuiJmm",
        "outputId": "77a25751-a149-470b-e072-bf4b2622b681"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'market_basket_analysis/datasets/original/aisles.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aisles_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket_basket_analysis/datasets/original/aisles.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m order_prods_prior_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket_basket_analysis/datasets/original/order_products__prior.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m order_prods_train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket_basket_analysis/datasets/original/order_products__train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'market_basket_analysis/datasets/original/aisles.csv'"
          ]
        }
      ],
      "source": [
        "aisles_df = pd.read_csv(\"market_basket_analysis/datasets/original/aisles.csv\")\n",
        "order_prods_prior_df = pd.read_csv(\"market_basket_analysis/datasets/original/order_products__prior.csv\")\n",
        "order_prods_train_df = pd.read_csv(\"market_basket_analysis/datasets/original/order_products__train.csv\")\n",
        "orders_df = pd.read_csv(\"market_basket_analysis/datasets/original/orders.csv\")\n",
        "products_df = pd.read_csv(\"market_basket_analysis/datasets/original/products.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QzRtmVXiJmp"
      },
      "outputs": [],
      "source": [
        "print(\"aisles shape: \", aisles_df.shape)\n",
        "print(\"order_prods_prior shape: \", order_prods_prior_df.shape)\n",
        "print(\"order_prods_train shape: \", order_prods_train_df.shape)\n",
        "print(\"orders shape: \", orders_df.shape)\n",
        "print(\"products shape: \", products_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUjMDa5ziJmp"
      },
      "outputs": [],
      "source": [
        "aisles_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCKSNkaiJmp"
      },
      "source": [
        "Reduce the number of aisles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaRcFgyviJmq"
      },
      "outputs": [],
      "source": [
        "aisles_df['aisle'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da_6NqqYiJmq"
      },
      "source": [
        "Map into 5 big categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOY0KgD-iJmq"
      },
      "outputs": [],
      "source": [
        "def categorize_aisle(aisle):\n",
        "    fresh_foods = ['fresh fruits', 'fresh vegetables', 'fresh herbs', 'poultry counter', 'seafood counter', 'meat counter', 'fresh dips tapenades']\n",
        "    packaged_foods = ['energy granola bars', 'instant foods', 'bakery desserts', 'pasta sauce', 'baking ingredients', 'bulk dried fruits vegetables', 'popcorn jerky', 'candy chocolate', 'cookies cakes', 'crackers', 'chips pretzels', 'cereal', 'dry pasta', 'grains rice dried goods', 'packaged vegetables fruits', 'trail mix snack mix', 'soup broth bouillon', 'canned meals beans', 'canned jarred vegetables', 'canned meat seafood', 'canned fruit applesauce', 'spices seasonings', 'condiments', 'granola', 'preserved dips spreads', 'salad dressing toppings']\n",
        "    beverages = ['coffee', 'tea', 'juice nectars', 'soft drinks', 'water seltzer sparkling water', 'energy sports drinks', 'protein meal replacements', 'beers coolers', 'red wines', 'white wines', 'spirits', 'specialty wines champagnes', 'cocoa drink mixes', 'frozen juice']\n",
        "    household_care = ['kitchen supplies', 'oral hygiene', 'soap', 'paper goods', 'shave needs', 'diapers wipes', 'trash bags liners', 'eye ear care', 'vitamins supplements', 'facial care', 'dish detergents', 'laundry', 'deodorants', 'air fresheners candles', 'baby bath body care', 'skin care', 'plates bowls cups flatware', 'cleaning products', 'first aid', 'feminine care', 'body lotions soap', 'muscles joints pain relief', 'beauty']\n",
        "    frozen_refrigerated = ['frozen meat seafood', 'frozen meals', 'frozen vegan vegetarian', 'frozen breads doughs', 'frozen breakfast', 'ice cream ice', 'ice cream toppings', 'refrigerated', 'milk', 'yogurt', 'butter', 'cream', 'soy lactosefree', 'refrigerated pudding desserts', 'frozen produce', 'frozen pizza', 'frozen appetizers sides', 'frozen dessert']\n",
        "\n",
        "    if aisle in fresh_foods:\n",
        "        return 'Fresh Foods'\n",
        "    elif aisle in packaged_foods:\n",
        "        return 'Packaged Foods'\n",
        "    elif aisle in beverages:\n",
        "        return 'Beverages'\n",
        "    elif aisle in household_care:\n",
        "        return 'Household & Personal Care'\n",
        "    elif aisle in frozen_refrigerated:\n",
        "        return 'Frozen & Refrigerated Items'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "# Apply the function to your dataframe\n",
        "aisles_df['aisle_category'] = aisles_df['aisle'].apply(categorize_aisle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jad3k2GLiJmr"
      },
      "outputs": [],
      "source": [
        "aisles_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLTzhI3uiJms"
      },
      "outputs": [],
      "source": [
        "aisles_df['aisle_category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAuFtBpciJms"
      },
      "outputs": [],
      "source": [
        "order_prods_prior_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l33NDTo-iJmt"
      },
      "outputs": [],
      "source": [
        "orders_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdSzdwLkiJmt"
      },
      "outputs": [],
      "source": [
        "products_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-KqgrapiJmu"
      },
      "outputs": [],
      "source": [
        "departments_df = pd.read_csv(\"market_basket_analysis/datasets/original/departments.csv\")\n",
        "departments_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsIpFqMiJmu"
      },
      "source": [
        "# 2. Merge datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0XIKigciJmv"
      },
      "source": [
        "### Order-Product Details:\n",
        "First, we merge the order_products data with orders to attach order-specific information to each product ordered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r58pmEPaiJmv"
      },
      "outputs": [],
      "source": [
        "order_products_merged = order_prods_prior_df.merge(orders_df, on='order_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbsHE5IRiJmv"
      },
      "outputs": [],
      "source": [
        "order_products_merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEiXVa-KiJmv"
      },
      "source": [
        "### Add Product Information:\n",
        "Merge the order_products_merged with products to attach product-specific details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m4VPo6giJmw"
      },
      "outputs": [],
      "source": [
        "order_products_merged = order_products_merged.merge(products_df, on='product_id', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZtSadXsiJmw"
      },
      "outputs": [],
      "source": [
        "order_products_merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzW2khfEiJmw"
      },
      "source": [
        "### Add Aisle and Department Information:\n",
        "Next, merge order_products_merged with aisles and departments to include aisle and department names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VhZWhXtiJmw"
      },
      "outputs": [],
      "source": [
        "order_products_merged = order_products_merged.merge(aisles_df, on='aisle_id', how='left')\n",
        "order_products_merged = order_products_merged.merge(departments_df, on='department_id', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul1m2JiDiJmw"
      },
      "outputs": [],
      "source": [
        "order_products_merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weOemZ9MiJmw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47SWtFyxiJmx"
      },
      "outputs": [],
      "source": [
        "order_products_merged.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjALDdw-iJmx"
      },
      "outputs": [],
      "source": [
        "order_products_merged.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb2DEHXHiJmx"
      },
      "source": [
        "# Data engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbSX6C-NiJmx"
      },
      "source": [
        "## Average Days Between Purchases:\n",
        "\n",
        "We can calculate the average days_since_prior_order for each user to capture their shopping frequency using the user_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuEgwEB5iJmx"
      },
      "outputs": [],
      "source": [
        "avg_days_between = order_products_merged.groupby('user_id')['days_since_prior_order'].mean().reset_index()\n",
        "avg_days_between.columns = ['user_id', 'avg_days_between_purchases']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWuX0gNIiJmy"
      },
      "outputs": [],
      "source": [
        "avg_days_between.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvM1bM3QiJmy"
      },
      "outputs": [],
      "source": [
        "avg_days_between.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92WnTwshiJmz"
      },
      "source": [
        "## Total Number of Orders:\n",
        "Count the number of unique order_id values for each user_id.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk4oEU2_iJmz"
      },
      "outputs": [],
      "source": [
        "total_orders = order_products_merged.groupby('user_id')['order_id'].nunique().reset_index()\n",
        "total_orders.columns = ['user_id', 'total_orders']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HIx7z8CiJmz"
      },
      "outputs": [],
      "source": [
        "total_orders.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9gwYY4RiJmz"
      },
      "source": [
        "## Average Number of Items per Order:\n",
        "Average count of product_id per order_id for each user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5PwYJNQiJm1"
      },
      "outputs": [],
      "source": [
        "items_per_order = order_products_merged.groupby(['user_id', 'order_id'])['product_id'].count().reset_index()\n",
        "avg_items_per_order = items_per_order.groupby('user_id')['product_id'].mean().reset_index()\n",
        "avg_items_per_order.columns = ['user_id', 'avg_items_per_order']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUp-yAbFiJm1"
      },
      "outputs": [],
      "source": [
        "avg_items_per_order.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OFiqA-DiJm1"
      },
      "source": [
        "## Most Frequent Day of the Week for Orders:\n",
        "Most common order_dow (day of the week) for each user.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AeICasHiJm2"
      },
      "outputs": [],
      "source": [
        "most_freq_dow = order_products_merged.groupby('user_id')['order_dow'].agg(lambda x: x.mode()[0]).reset_index()\n",
        "most_freq_dow.columns = ['user_id', 'most_freq_day']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA-VL7vkiJm2"
      },
      "outputs": [],
      "source": [
        "most_freq_dow.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dGy7_kHiJm2"
      },
      "source": [
        "## Most Frequent Hour of the Day for Orders:\n",
        "Mode of order_hour_of_day for each user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgLlUASiiJm3"
      },
      "outputs": [],
      "source": [
        "most_freq_hour = order_products_merged.groupby('user_id')['order_hour_of_day'].agg(lambda x: x.mode()[0]).reset_index()\n",
        "most_freq_hour.columns = ['user_id', 'most_freq_hour']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm6W5HsPiJm3"
      },
      "outputs": [],
      "source": [
        "most_freq_hour.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWgvTzU3iJm3"
      },
      "source": [
        "## Average Time Between Orders for Specific Products:\n",
        "For each user-product pair, the average days_since_prior_order.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wtxCBQSiJm3"
      },
      "outputs": [],
      "source": [
        "avg_days_product = order_products_merged.groupby(['user_id', 'product_id'])['days_since_prior_order'].mean().reset_index()\n",
        "avg_days_product.columns = ['user_id', 'product_id', 'avg_days_product_purchase']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJs-7k8JiJm3"
      },
      "outputs": [],
      "source": [
        "avg_days_product.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACcSO1UXiJm4"
      },
      "source": [
        "## Percentage of Orders with a Specific Product:\n",
        "\n",
        "How often each product appears in orders as a proportion of the user’s total orders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnAc0n8tiJm4"
      },
      "outputs": [],
      "source": [
        "product_orders = order_products_merged.groupby(['user_id', 'product_id'])['order_id'].nunique().reset_index()\n",
        "total_orders = order_products_merged.groupby('user_id')['order_id'].nunique().reset_index()\n",
        "merged = product_orders.merge(total_orders, on='user_id', suffixes=('_product', '_total'))\n",
        "merged['product_order_ratio'] = merged['order_id_product'] / merged['order_id_total']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XYu5e7giJm5"
      },
      "outputs": [],
      "source": [
        "merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z61jtLDxiJm5"
      },
      "outputs": [],
      "source": [
        "product_order_ratio = merged.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToiQFI-BiJm6"
      },
      "source": [
        "## Recency of Last Purchase for Each Product:\n",
        "\n",
        " Identify the last order number for each product and calculate the difference from the user’s most recent order.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTy2ggjiiJm6"
      },
      "outputs": [],
      "source": [
        "last_purchase = order_products_merged.groupby(['user_id', 'product_id'])['order_number'].max().reset_index()\n",
        "recent_order = order_products_merged.groupby('user_id')['order_number'].max().reset_index()\n",
        "merged = last_purchase.merge(recent_order, on='user_id', suffixes=('_product', '_recent'))\n",
        "merged['recency_last_purchase'] = merged['order_number_recent'] - merged['order_number_product']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnFbRawZiJm6"
      },
      "outputs": [],
      "source": [
        "recency_last_purchase = merged.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtjFU3MmiJm7"
      },
      "outputs": [],
      "source": [
        "recency_last_purchase.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNX9QnGbiJm7"
      },
      "source": [
        "## Reorder Ratio for Each Product:\n",
        "\n",
        "Calculate the reorder rate as the ratio of times a product was reordered to the total times it was ordered.\n",
        "\n",
        "Source Features: user_id, product_id, reordered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XqimgHRiJm7"
      },
      "outputs": [],
      "source": [
        "product_reorders = order_products_merged.groupby(['user_id', 'product_id'])['reordered'].sum().reset_index()\n",
        "product_orders = order_products_merged.groupby(['user_id', 'product_id'])['order_id'].count().reset_index()\n",
        "merged = product_reorders.merge(product_orders, on=['user_id', 'product_id'])\n",
        "merged['reorder_ratio'] = merged['reordered'] / merged['order_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn1ELd97iJm8"
      },
      "outputs": [],
      "source": [
        "reorder_ratio = merged.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqCN7S3FiJm8"
      },
      "outputs": [],
      "source": [
        "reorder_ratio.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbd9sK1piJm8"
      },
      "source": [
        "## Product Popularity in Each Aisle:\n",
        "Calculate the total orders containing products in each aisle.\n",
        "\n",
        "Source Features: product_id, aisle_id, order_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x87zwFNiJm8"
      },
      "outputs": [],
      "source": [
        "aisle_popularity = order_products_merged.groupby('aisle_id')['order_id'].nunique().reset_index()\n",
        "aisle_popularity.columns = ['aisle_id', 'aisle_popularity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwa0DbS2iJm8"
      },
      "outputs": [],
      "source": [
        "aisle_popularity.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmm-BN6SiJm9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Merge order details to get days_since_prior_order for each user-product order\n",
        "merged_orders = order_prods_prior_df.merge(orders_df[['order_id', 'user_id', 'order_number', 'days_since_prior_order']],\n",
        "                                           on='order_id', how='left')\n",
        "\n",
        "# Sort by user, product, and order number to get chronological order for each product per user\n",
        "merged_orders = merged_orders.sort_values(by=['user_id', 'product_id', 'order_number'])\n",
        "\n",
        "# Calculate days to the next purchase for each user-product combination\n",
        "merged_orders['days_until_next_order'] = merged_orders.groupby(['user_id', 'product_id'])['days_since_prior_order'].shift(-1)\n",
        "\n",
        "# Reset index for cleaner merging if needed\n",
        "merged_orders.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# At this point, 'days_until_next_order' represents the next purchase time\n",
        "# If a row has NaN for 'days_until_next_order', it indicates the last purchase for that user-product\n",
        "\n",
        "# Keep only the relevant columns for the modeling DataFrame\n",
        "next_purchase_time = merged_orders[['user_id', 'product_id', 'order_id', 'days_until_next_order']].copy()\n",
        "\n",
        "# Rename 'days_until_next_order' to 'next_purchase_time' for clarity\n",
        "next_purchase_time.rename(columns={'days_until_next_order': 'next_purchase_time'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhNzSeaTiJm9"
      },
      "outputs": [],
      "source": [
        "next_purchase_time.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1SSegdYiJm9"
      },
      "outputs": [],
      "source": [
        "next_purchase_time.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlxRA-rBiJm9"
      },
      "source": [
        "## Combining Features for Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF3gMVd0iJm-"
      },
      "source": [
        "### Merge User-Level Features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crZ3WXF9iJm-"
      },
      "outputs": [],
      "source": [
        "# Assume user_features contains user-level features like 'avg_days_between_purchases', 'total_orders', etc.\n",
        "user_features = avg_days_between.merge(total_orders, on='user_id', how='left')\n",
        "user_features = user_features.merge(avg_items_per_order, on='user_id', how='left')\n",
        "user_features = user_features.merge(most_freq_dow, on='user_id', how='left')\n",
        "user_features = user_features.merge(most_freq_hour, on='user_id', how='left')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwSkm0vliJm-"
      },
      "source": [
        "### Merge Product-Level Features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2H29ePjiJm_"
      },
      "outputs": [],
      "source": [
        "# Assume product_features contains product-level features like 'avg_days_product_purchase', 'product_order_ratio', etc.\n",
        "product_features = avg_days_product.merge(product_order_ratio, on=['user_id', 'product_id'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT1Trz4ZiJm_"
      },
      "outputs": [],
      "source": [
        "product_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvbXI39XiJm_"
      },
      "source": [
        "### Merge User-Product Interaction Features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlR6ob55iJm_"
      },
      "outputs": [],
      "source": [
        "# Assume user_product_features contains user-product interaction features like 'recency_last_purchase', 'reorder_ratio', etc.\n",
        "user_product_features = recency_last_purchase.merge(reorder_ratio, on=['user_id', 'product_id'], how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO6rawMGiJnA"
      },
      "outputs": [],
      "source": [
        "user_product_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOVcI34ziJnA"
      },
      "outputs": [],
      "source": [
        "user_product_features.to_csv('user_product_features.csv', index=False)\n",
        "user_features.to_csv('user_features.csv', index=False)\n",
        "product_features.to_csv('product_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-X8Hd8BiJnA"
      },
      "source": [
        "# Predicting Product Demand Frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m1Sh4PViJnA"
      },
      "outputs": [],
      "source": [
        "# Calculate average days since prior order for each product\n",
        "avg_demand_interval = order_products_merged.groupby('product_id')['days_since_prior_order'].mean().reset_index()\n",
        "avg_demand_interval.columns = ['product_id', 'average_demand_interval']\n",
        "avg_demand_interval.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oimqao0LiJnB"
      },
      "outputs": [],
      "source": [
        "product_order_counts = order_products_merged.groupby('product_id').size().reset_index(name='total_orders')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOUEcNKoiJnB"
      },
      "outputs": [],
      "source": [
        "avg_cart_position = order_products_merged.groupby('product_id')['add_to_cart_order'].mean().reset_index()\n",
        "avg_cart_position.columns = ['product_id', 'average_cart_position']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVu5qRMniJnB"
      },
      "outputs": [],
      "source": [
        "product_reorder_counts = order_products_merged.groupby('product_id').agg(\n",
        "    total_orders=('order_id', 'count'),\n",
        "    reorders=('reordered', 'sum')\n",
        ").reset_index()\n",
        "product_reorder_counts['reorder_probability'] = product_reorder_counts['reorders'] / product_reorder_counts['total_orders']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJI7rDR9iJnB"
      },
      "outputs": [],
      "source": [
        "unique_user_counts = order_products_merged.groupby('product_id')['user_id'].nunique().reset_index()\n",
        "unique_user_counts.columns = ['product_id', 'unique_users']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZl4BEQZiJnC"
      },
      "outputs": [],
      "source": [
        "recent_purchase = order_products_merged.groupby('product_id')['days_since_prior_order'].max().reset_index()\n",
        "recent_purchase.columns = ['product_id', 'recency_last_purchase']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJbt8K86iJnC"
      },
      "outputs": [],
      "source": [
        "user_product_intervals = order_products_merged.groupby(['product_id', 'user_id'])['days_since_prior_order'].mean().reset_index()\n",
        "avg_user_product_interval = user_product_intervals.groupby('product_id')['days_since_prior_order'].mean().reset_index()\n",
        "avg_user_product_interval.columns = ['product_id', 'avg_user_order_interval']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brNsSROjiJnC"
      },
      "outputs": [],
      "source": [
        "# Start with the target variable DataFrame\n",
        "modeling_df = avg_demand_interval\n",
        "\n",
        "# Merge each feature into the modeling DataFrame\n",
        "modeling_df = modeling_df.merge(product_order_counts, on='product_id', how='left')\n",
        "modeling_df = modeling_df.merge(avg_cart_position, on='product_id', how='left')\n",
        "modeling_df = modeling_df.merge(product_reorder_counts[['product_id', 'reorder_probability']], on='product_id', how='left')\n",
        "modeling_df = modeling_df.merge(unique_user_counts, on='product_id', how='left')\n",
        "modeling_df = modeling_df.merge(recent_purchase, on='product_id', how='left')\n",
        "modeling_df = modeling_df.merge(avg_user_product_interval, on='product_id', how='left')\n",
        "\n",
        "# Example of encoding categorical features if needed\n",
        "# modeling_df = pd.get_dummies(modeling_df, columns=['aisle', 'department'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjtkiZ7giJnC"
      },
      "outputs": [],
      "source": [
        "modeling_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wne6SYfiJnD"
      },
      "outputs": [],
      "source": [
        "products_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYglcWAfiJnD"
      },
      "outputs": [],
      "source": [
        "modeling_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi3UpnbTiJnD"
      },
      "outputs": [],
      "source": [
        "# Step 6: Handle missing values\n",
        "modeling_df.fillna(0, inplace=True)\n",
        "modeling_df.dropna(subset=['average_demand_interval'], inplace=True)\n",
        "\n",
        "# Verify final DataFrame\n",
        "modeling_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD6mLPyRiJnD"
      },
      "outputs": [],
      "source": [
        "modeling_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW6wMw68iJnD"
      },
      "outputs": [],
      "source": [
        "modeling_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "SK4gjiL_iJnE",
        "outputId": "4a782d25-2c72-42d2-ed15-dd695a9e2e0c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'modeling_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2851fdd5c983>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodeling_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/modeling_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'modeling_df' is not defined"
          ]
        }
      ],
      "source": [
        "modeling_df.to_csv('/content/sample_data/modeling_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aONjgIQiJnE"
      },
      "source": [
        "# Split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i2bGdcdEiJnE"
      },
      "outputs": [],
      "source": [
        "modeling_df = pd.read_csv('/content/sample_data/modeling_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jwePHWJriJnE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = ['total_orders', 'average_cart_position', 'reorder_probability',\n",
        "                    'unique_users', 'recency_last_purchase', 'avg_user_order_interval']\n",
        "target = 'average_demand_interval'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(modeling_df[features], modeling_df[target], test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pf-Fjp_iJnE",
        "outputId": "a77e9ebb-2149-45d0-fa1a-480218d1632b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39741, 6) (9936, 6) (39741,) (9936,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq28a9HSiJnF"
      },
      "source": [
        "# Scale the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ihTMwUx4iJnF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "columns_to_scale = [ 'total_orders', 'average_cart_position', 'reorder_probability',\n",
        "                    'unique_users', 'recency_last_purchase', 'avg_user_order_interval']\n",
        "\n",
        "scaler = StandardScaler()  # Or choose another scaler as needed\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKXvSOB4iJnF",
        "outputId": "a41c9148-681f-45b5-efb3-e44d3b724742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.43251884 10.1033668   6.39855304 ...  9.49046838 12.55811898\n",
            " 10.25350696]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train_scaled, y_train)\n",
        "y_pred_linear = linear_model.predict(X_test_scaled)\n",
        "print(y_pred_linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh5lHikbiJnG",
        "outputId": "facb1ad4-d927-4628-83cd-9221fea9ebce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.4325047  10.10342754  6.39859466 ...  9.49054586 12.55808647\n",
            " 10.25357024]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0)  # we can change our aplha, but dispite different values of alpha we are getting the same results\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
        "print(y_pred_ridge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtTZdUYUiJnG",
        "outputId": "49507cf0-03f4-42cb-95f5-ea1678ea9409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.41458626  9.91644057  6.73075517 ...  9.93590776 12.03413791\n",
            "  9.96140595]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "print(y_pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns9mn_nLiJnG",
        "outputId": "4b592644-0a84-4519-ec9e-b1e3bdcd20e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.45193825 10.15166983  6.8171162  ...  9.66882448 12.24478698\n",
            " 10.00594131]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svr_model = SVR(kernel='rbf')  # 'rbf' kernel for non-linear relationships\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "y_pred_svr = svr_model.predict(X_test_scaled)\n",
        "print(y_pred_svr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHJ4TzqriJnH",
        "outputId": "255fedbd-e440-4a44-ff5a-40f23bf3ad61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Linear Regression ---\n",
            "Mean Absolute Error (MAE): 0.691\n",
            "Mean Squared Error (MSE): 1.065\n",
            "Root Mean Squared Error (RMSE): 1.032\n",
            "R-squared (R²): 0.866\n",
            "\n",
            "--- Ridge Regression ---\n",
            "Mean Absolute Error (MAE): 0.691\n",
            "Mean Squared Error (MSE): 1.065\n",
            "Root Mean Squared Error (RMSE): 1.032\n",
            "R-squared (R²): 0.866\n",
            "\n",
            "--- Random Forest Regressor ---\n",
            "Mean Absolute Error (MAE): 0.657\n",
            "Mean Squared Error (MSE): 1.023\n",
            "Root Mean Squared Error (RMSE): 1.012\n",
            "R-squared (R²): 0.872\n",
            "\n",
            "--- Support Vector Regressor ---\n",
            "Mean Absolute Error (MAE): 0.640\n",
            "Mean Squared Error (MSE): 1.034\n",
            "Root Mean Squared Error (RMSE): 1.017\n",
            "R-squared (R²): 0.870\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# a function that can print us the Model evaluations.\n",
        "def evaluate_model(y_test, y_pred, model_name):\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
        "    print(f\"R-squared (R²): {r2:.3f}\\n\")\n",
        "\n",
        "# function call for each of the model\n",
        "evaluate_model(y_test, y_pred_linear, \"Linear Regression\")\n",
        "evaluate_model(y_test, y_pred_ridge, \"Ridge Regression\")\n",
        "evaluate_model(y_test, y_pred_rf, \"Random Forest Regressor\")\n",
        "evaluate_model(y_test, y_pred_svr, \"Support Vector Regressor\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wf2hj5VApIj6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "LsNpUuoSiJnH"
      },
      "source": [
        "We can see tha t the Random Forest and SVR is giving us the exactly same results and also they are the best performing models when\n",
        "we consider the Mean absolute error and R squared error .\n",
        "The R squared error for Random forest is the highest implicating a 87.2% variance in the target variabe .\n",
        "The SVR has lowest MAE , which means it has tge least average error b/w actual and pred values."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "xUC_0txbiJnH"
      },
      "source": [
        "Now, let us further fine tune the Random Forest and SVR usinf GridSearchCV and RandomisedSearchCV and see if there is any further improvemnts in the performance'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "t-1sU_h6pDUk"
      }
    },
    {
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to tune. Removed 'normalize'\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False]  # Keep other parameters\n",
        "}\n",
        "\n",
        "# Set up the LinearRegression model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Set up GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=linear_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score (MSE):\", -grid_search.best_score_)\n",
        "\n",
        "# Make predictions using the best model from GridSearchCV\n",
        "best_linear_model = grid_search.best_estimator_\n",
        "y_pred_linear_ht = best_linear_model.predict(X_test_scaled)\n",
        "\n",
        "# Print predictions\n",
        "print(\"Predictions:\", y_pred_linear_ht)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx9_LUU2q-io",
        "outputId": "3ebcbb59-7d63-4e19-97ff-e01197d5cde9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'fit_intercept': True, 'positive': False}\n",
            "Best Score (MSE): 1.0653793417009676\n",
            "Predictions: [12.43251884 10.1033668   6.39855304 ...  9.49046838 12.55811898\n",
            " 10.25350696]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# Initialize PCA with desired number of components\n",
        "pca = PCA(n_components=5)\n",
        "\n",
        "# Fit PCA on training data and transform\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "# Transform test data using fitted PCA\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Initialize Ridge model\n",
        "ridge_model = Ridge(alpha=0.01)  # Remove pca_n_components\n",
        "\n",
        "# Fit Ridge model on PCA-transformed data\n",
        "ridge_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict on PCA-transformed test data\n",
        "y_pred_ridge_ht= ridge_model.predict(X_test_pca)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "khpthSIxqiVF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for the best split\n",
        "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
        "}\n",
        "\n",
        "# Set up the RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score (MSE):\", -grid_search.best_score_)\n",
        "\n",
        "# Make predictions using the best model from GridSearchCV\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_rf_ht = best_rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Print predictions\n",
        "print(\"Predictions:\", y_pred_rf_ht)\n"
      ],
      "metadata": {
        "id": "uqveIDTRsCfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'epsilon': [0.01, 0.1, 0.2, 0.5],  # Epsilon parameter\n",
        "    'kernel': ['linear', 'rbf', 'poly'],  # Type of kernel to use\n",
        "    'degree': [2, 3, 4],  # Degree of the polynomial kernel function (only for 'poly' kernel)\n",
        "    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
        "}\n",
        "\n",
        "# Set up the SVR model with RBF kernel\n",
        "svr_model = SVR()\n",
        "\n",
        "# Set up GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score (MSE):\", -grid_search.best_score_)\n",
        "\n",
        "# Make predictions using the best model from GridSearchCV\n",
        "best_svr_model = grid_search.best_estimator_\n",
        "y_pred_svr_ht = best_svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Print predictions\n",
        "print(\"Predictions:\", y_pred_svr_ht)\n"
      ],
      "metadata": {
        "id": "aisr5M5gsCsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# a function that can print us the Model evaluations.\n",
        "def evaluate_model(y_test, y_pred, model_name):\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
        "    print(f\"R-squared (R²): {r2:.3f}\\n\")\n",
        "\n",
        "# function call for each of the model\n",
        "evaluate_model(y_test, y_pred_linear_ht, \"Linear Regression\")\n",
        "evaluate_model(y_test, y_pred_ridge_ht, \"Ridge Regression\")\n",
        "evaluate_model(y_test, y_pred_rf_ht, \"Random Forest Regressor\")\n",
        "evaluate_model(y_test, y_pred_svr_ht, \"Support Vector Regressor\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mNhQtnWMpakw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}